{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ood_detection_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhCSQUULXQhcdZyBf1WsMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "390517301e12476ab65513d2ed72e0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2aef02eb8dc84743a2a00e164975a227",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42bd4f85411447f79e926f435cbac3ea",
              "IPY_MODEL_6d4b516d13db4930af9f7127249301c5"
            ]
          }
        },
        "2aef02eb8dc84743a2a00e164975a227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42bd4f85411447f79e926f435cbac3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15bbee6a2a5d48c9a02f075ae600f38c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_addc4f77131d4ae0a7c6ef02e08de6dd"
          }
        },
        "6d4b516d13db4930af9f7127249301c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61b218fab6764f52ad118328617f485e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 79656302.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3315bebb5c164ca48213b43199c90f1f"
          }
        },
        "15bbee6a2a5d48c9a02f075ae600f38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "addc4f77131d4ae0a7c6ef02e08de6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61b218fab6764f52ad118328617f485e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3315bebb5c164ca48213b43199c90f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstrakhantsevaAA/confidence_estimation_resnet/blob/master/ood_detection_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzn8ZsJ1PkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/AstrakhantsevaAA/confidence_estimation_resnet.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0oVb5r01RMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torch.autograd import Variable\n",
        "from confidence_estimation_resnet.model import resnet\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11B_BTqh1RS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0da9fd4-f6d8-4b9b-aa9a-92c1aea6e780"
      },
      "source": [
        "process = ['baseline',  'confidence', 'confidence_scaling']\n",
        "mode = process[2]\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "cudnn.deterministic = True\n",
        "cudnn.benchmark = False\n",
        "path = 'confidence_estimation_resnet/checkpoint'\n",
        "filename = {\n",
        "            'baseline': f'{path}/checkpoint_CIFAR_resnet_0.0.pth', \n",
        "            'confidence': f'{path}/checkpoint_CIFAR_resnet_0.3.pth',\n",
        "            'confidence_scaling': f'{path}/checkpoint_CIFAR_resnet_0.3.pth'\n",
        "}\n",
        "\n",
        "validation = False\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN_scS8H1Rbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "390517301e12476ab65513d2ed72e0f1",
            "2aef02eb8dc84743a2a00e164975a227",
            "42bd4f85411447f79e926f435cbac3ea",
            "6d4b516d13db4930af9f7127249301c5",
            "15bbee6a2a5d48c9a02f075ae600f38c",
            "addc4f77131d4ae0a7c6ef02e08de6dd",
            "61b218fab6764f52ad118328617f485e",
            "3315bebb5c164ca48213b43199c90f1f"
          ]
        },
        "outputId": "b7ce56a4-1f22-4fe7-a6c5-481ced377208"
      },
      "source": [
        "###########################\n",
        "### Set up data loaders ###\n",
        "###########################\n",
        "\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)])\n",
        "\n",
        "# # tinyImageNet_crop and LSUN_crop are 36x36, so crop to 32x32\n",
        "crop_transform = transforms.Compose([transforms.CenterCrop(size=(32, 32)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean, std)])\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "ind_dataset = datasets.CIFAR10(root='data/',\n",
        "                                   train=False,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "\n",
        "# download TinyImageNet\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "data_path = 'IMagenet/tiny-imagenet-200/val/'\n",
        "ood_dataset = datasets.ImageFolder(root=data_path, transform=crop_transform)\n",
        "\n",
        "\n",
        "ind_loader = torch.utils.data.DataLoader(dataset=ind_dataset,\n",
        "                                         batch_size=100,\n",
        "                                         shuffle=False,\n",
        "                                         pin_memory=True,\n",
        "                                         num_workers=2)\n",
        "\n",
        "ood_loader = torch.utils.data.DataLoader(dataset=ood_dataset,\n",
        "                                         batch_size=100,\n",
        "                                         shuffle=False,\n",
        "                                         pin_memory=True,\n",
        "                                         num_workers=2)\n",
        "if validation:\n",
        "    # Limit dataset to first 1000 samples for validation and fine-tuning\n",
        "    # Based on validation procedure from https://arxiv.org/abs/1706.02690\n",
        "    ood_loader.dataset.imgs = ood_loader.dataset.imgs[:1000]\n",
        "    ood_loader.dataset.__len__ = 1000\n",
        "else:\n",
        "    ood_loader.dataset.imgs = ood_loader.dataset.imgs[1000:]\n",
        "    ood_loader.dataset.__len__ = len(ood_loader.dataset.imgs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "390517301e12476ab65513d2ed72e0f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 31.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Checking out files: 100% (120206/120206), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eshUhwjw1RaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "710c2821-c336-40d5-abe4-4127a1a555b2"
      },
      "source": [
        "##############################\n",
        "### Load pre-trained model ###\n",
        "##############################\n",
        "\n",
        "cnn = resnet.resnet18(num_classes=num_classes)\n",
        "\n",
        "pretrained_dict = torch.load(filename[mode])\n",
        "cnn.load_state_dict(pretrained_dict['net'])\n",
        "cnn = cnn.to(device)\n",
        "if device == 'cuda':\n",
        "    cnn = torch.nn.DataParallel(cnn)\n",
        "\n",
        "cnn.eval()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (confidence): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2v72yr-1RYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################################\n",
        "### Evaluate out-of-distribution detection ###\n",
        "##############################################\n",
        "\n",
        "def evaluate(data_loader, mode):\n",
        "    out = []\n",
        "    xent = nn.CrossEntropyLoss()\n",
        "    for data in data_loader:\n",
        "        if type(data) == list:\n",
        "            images, labels = data\n",
        "        else:\n",
        "            images = data\n",
        "\n",
        "        images = Variable(images, requires_grad=True).cuda()\n",
        "        images.retain_grad()\n",
        "\n",
        "        if mode == 'confidence':\n",
        "            _, confidence = cnn(images)\n",
        "            confidence = torch.sigmoid(confidence)\n",
        "            confidence = confidence.data.cpu().numpy()\n",
        "            out.append(confidence)\n",
        "\n",
        "        elif mode == 'confidence_scaling':\n",
        "            epsilon = 0.001\n",
        "\n",
        "            cnn.zero_grad()\n",
        "            _, confidence = cnn(images)\n",
        "            confidence = torch.sigmoid(confidence).view(-1)\n",
        "            loss = torch.mean(-torch.log(confidence))\n",
        "            loss.backward()\n",
        "\n",
        "            images = images - epsilon * torch.sign(images.grad)\n",
        "            images = Variable(images.data, requires_grad=True)\n",
        "\n",
        "            _, confidence = cnn(images)\n",
        "            confidence = torch.sigmoid(confidence)\n",
        "            confidence = confidence.data.cpu().numpy()\n",
        "            out.append(confidence)\n",
        "\n",
        "        elif mode == 'baseline':\n",
        "            # https://arxiv.org/abs/1610.02136\n",
        "            pred, _ = cnn(images)\n",
        "            pred = F.softmax(pred, dim=-1)\n",
        "            pred = torch.max(pred.data, 1)[0]\n",
        "            pred = pred.cpu().numpy()\n",
        "            out.append(pred)\n",
        "\n",
        "    out = np.concatenate(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK2rvcVXSE3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tpr95(ind_confidences, ood_confidences):\n",
        "    #calculate the falsepositive error when tpr is 95%\n",
        "    Y1 = ood_confidences\n",
        "    X1 = ind_confidences\n",
        "\n",
        "    start = np.min([np.min(X1), np.min(Y1)])\n",
        "    end = np.max([np.max(X1), np.max(Y1)])\n",
        "    gap = (end - start) / 100000\n",
        "\n",
        "    total = 0.0\n",
        "    fpr = 0.0\n",
        "    for delta in np.arange(start, end, gap):\n",
        "        tpr = np.sum(np.sum(X1 >= delta)) / np.float(len(X1))\n",
        "        error2 = np.sum(np.sum(Y1 > delta)) / np.float(len(Y1))\n",
        "        if tpr <= 0.9505 and tpr >= 0.9495:\n",
        "            fpr += error2\n",
        "            total += 1\n",
        "\n",
        "    fprBase = fpr / total\n",
        "\n",
        "    return fprBase\n",
        "\n",
        "\n",
        "def detection(ind_confidences, ood_confidences, n_iter=100000, return_data=False):\n",
        "    # calculate the minimum detection error\n",
        "    Y1 = ood_confidences\n",
        "    X1 = ind_confidences\n",
        "\n",
        "    start = np.min([np.min(X1), np.min(Y1)])\n",
        "    end = np.max([np.max(X1), np.max(Y1)])\n",
        "    gap = (end - start) / n_iter\n",
        "\n",
        "    best_error = 1.0\n",
        "    best_delta = None\n",
        "    all_thresholds = []\n",
        "    all_errors = []\n",
        "    for delta in np.arange(start, end, gap):\n",
        "        tpr = np.sum(np.sum(X1 < delta)) / np.float(len(X1))\n",
        "        error2 = np.sum(np.sum(Y1 > delta)) / np.float(len(Y1))\n",
        "        detection_error = (tpr + error2) / 2.0\n",
        "\n",
        "        if return_data:\n",
        "            all_thresholds.append(delta)\n",
        "            all_errors.append(detection_error)\n",
        "\n",
        "        if detection_error < best_error:\n",
        "            best_error = np.minimum(best_error, detection_error)\n",
        "            best_delta = delta\n",
        "\n",
        "    if return_data:\n",
        "        return best_error, best_delta, all_errors, all_thresholds\n",
        "    else:\n",
        "        return best_error, best_delta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34i1MqG81RWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4d2de200-0219-4a9e-de0b-60fc65bacb2e"
      },
      "source": [
        "ind_scores = evaluate(ind_loader, mode)\n",
        "ind_labels = np.ones(ind_scores.shape[0])\n",
        "\n",
        "ood_scores = evaluate(ood_loader, mode)\n",
        "ood_labels = np.zeros(ood_scores.shape[0])\n",
        "\n",
        "labels = np.concatenate([ind_labels, ood_labels])\n",
        "scores = np.concatenate([ind_scores, ood_scores])\n",
        "\n",
        "fpr_at_95_tpr = tpr95(ind_scores, ood_scores)\n",
        "detection_error, best_delta = detection(ind_scores, ood_scores)\n",
        "auroc = metrics.roc_auc_score(labels, scores)\n",
        "aupr_in = metrics.average_precision_score(labels, scores)\n",
        "aupr_out = metrics.average_precision_score(-1 * labels + 1, 1 - scores)\n",
        "state = {\n",
        "    \"Method\" : mode,\n",
        "    \"TPR95\": fpr_at_95_tpr,\n",
        "    \"Detection_error\": detection_error,\n",
        "    \"Best_threshold\": best_delta,\n",
        "    \"AUROC\": auroc,\n",
        "    \"AUPR_IN\": aupr_in,\n",
        "    \"AUPR_OUT\": aupr_out,\n",
        "}\n",
        "if not os.path.isdir('metrics'):\n",
        "    os.mkdir('metrics')\n",
        "torch.save(state, f'./metrics/metrics_{mode}.pth')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Method: \" + mode)\n",
        "print(\"TPR95 (lower is better): \", fpr_at_95_tpr)\n",
        "print(\"Detection error (lower is better): \", detection_error)\n",
        "print(\"Best threshold:\", best_delta)\n",
        "print(\"AUROC (higher is better): \", auroc)\n",
        "print(\"AUPR_IN (higher is better): \", aupr_in)\n",
        "print(\"AUPR_OUT (higher is better): \", aupr_out)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Method: confidence_scaling\n",
            "TPR95 (lower is better):  0.8746530303030304\n",
            "Detection error (lower is better):  0.3387\n",
            "Best threshold: 0.7516522330425641\n",
            "AUROC (higher is better):  0.71207959\n",
            "AUPR_IN (higher is better):  0.7412124563283489\n",
            "AUPR_OUT (higher is better):  0.6707170447658624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw84dm-u1Hk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "14260a7c-1a67-45b1-fa5d-fad9b9f8d47c"
      },
      "source": [
        "ranges = (np.min(scores), np.max(scores))\n",
        "plt.figure()\n",
        "sns.distplot(ind_scores.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='In-distribution')\n",
        "sns.distplot(ood_scores.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='Out-of-distribution')\n",
        "plt.xlabel('Confidence')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "if not os.path.isdir('plots'):\n",
        "    os.mkdir('plots')\n",
        "plt.savefig(f'plots/confidence_hist_{mode}.png')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}